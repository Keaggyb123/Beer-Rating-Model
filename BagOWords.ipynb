{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8212bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e74a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts sentences to tokens\n",
    "punct = string.punctuation\n",
    "def word2token(sent):\n",
    "        t = sent.lower() # lowercase string\n",
    "        t = \"\".join([c for c in t if not (c in punct)]) # non-punct characters\n",
    "        words = word_tokenize(t)# tokenizes\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8f5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in first 500,001 entries of DS\n",
    "file = 'beer.json.gz'\n",
    "def readData(path):\n",
    "    x = gzip.open(path)\n",
    "    for l in x:\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70b766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "amount_in_train = 400000\n",
    "for d in readData(file):\n",
    "    if count > 500000:\n",
    "        break\n",
    "    if count < amount_in_train:\n",
    "        X_train.append(d['review/text'])\n",
    "        y_train.append(d[\"review/overall\"])\n",
    "    if count > amount_in_train:\n",
    "        X_test.append(d['review/text'])\n",
    "        y_test.append(d[\"review/overall\"])\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cbe3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counts(train):\n",
    "    wordCount = defaultdict(int)\n",
    "    for t in train:\n",
    "        words = word2token(t)\n",
    "        for w in words:\n",
    "            wordCount[w] += 1\n",
    "    return wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bac89158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word counts dictionary\n",
    "wordCount = word_counts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7815a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [w[1] for w in counts[:200]]\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8821a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(data):\n",
    "    feat = np.zeros(len(wordSet)+1)\n",
    "    r = word2token(data)\n",
    "    for w in r:\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat[-1] = 1 # offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433cf670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [feature(d) for d in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09518db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<375000x201 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 17941988 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.array(train_x).astype(np.uint8)\n",
    "sparse_train = csr_matrix(train_x)\n",
    "sparse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e57d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [feature(d) for d in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cf330e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<125000x201 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 6003815 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.array(test_x).astype(np.uint8)\n",
    "sparse_test = csr_matrix(test_x)\n",
    "sparse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "915562b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47252587274477115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of ridge regression, no hyper tuning\n",
    "clf = linear_model.Ridge()\n",
    "clf.fit(sparse_train, y_train)\n",
    "predictions = clf.predict(sparse_test)\n",
    "mse = mean_absolute_error(y_test, predictions)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7715ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first optimize lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da111a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.472523879856653),\n",
       " (100, 0.47251526007655803),\n",
       " (500, 0.47245607140926665)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizing lambda\n",
    "lambs = [10,100,500]\n",
    "arr = []\n",
    "for x in lambs:\n",
    "    clf = linear_model.Ridge(x)\n",
    "    clf.fit(sparse_train, y_train)\n",
    "    predictions = clf.predict(sparse_test)\n",
    "    mse = mean_absolute_error(y_test, predictions)\n",
    "    arr.append((x,mse))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246216cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20000, 0.4718509769979457), (21000, 0.4718790960389748)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizing lambda\n",
    "lambs = [20000,21000]\n",
    "arr = []\n",
    "for x in lambs:\n",
    "    clf = linear_model.Ridge(x)\n",
    "    clf.fit(sparse_train, y_train)\n",
    "    predictions = clf.predict(sparse_test)\n",
    "    mse = mean_absolute_error(y_test, predictions)\n",
    "    arr.append((x,mse))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ebc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremely large regualizer of 20,000 resulted in best mae of .4707\n",
    "# means that we may be over fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a98ed5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bad         -0.124806\n",
       "no          -0.082371\n",
       "thin        -0.070540\n",
       "not         -0.062409\n",
       "decent      -0.055044\n",
       "               ...   \n",
       "balanced     0.085017\n",
       "smooth       0.100752\n",
       "easy         0.104984\n",
       "great        0.117258\n",
       "drinkable    0.118000\n",
       "Length: 200, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 most negative and most positive words\n",
    "theta = clf.coef_\n",
    "lc ={ w:theta[wordId[w]] for w in wordId}\n",
    "pd.Series(lc).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a620f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4717042654255452"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove values over 5\n",
    "predictions = clf.predict(sparse_test)\n",
    "less_5 = [5 if p>5 else p for p in predictions]\n",
    "mean_squared_error(y_test, predictions)\n",
    "mean_absolute_error(y_test, predictions)\n",
    "#mean_squared_error(y_test, less_5)\n",
    "mean_absolute_error(y_test, less_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ee846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
